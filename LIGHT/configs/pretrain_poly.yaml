# base settings
output_dir: './_runs/'  

# model settings
exp_name: "test"
resume: False
checkpoint_path: "./_runs/pretrain_poly__all_data__v0/models/model_epoch_500.pth"

task: "pretrain"

poly_num_tokens: 1000
padding_token_id: -100
mask_token_id: -1
max_len: 32
mask_ratio: 0.15

# dataset settings
train_datasets: ["MapText_train"] #, "Rumsey1_train", "Rumsey2_train"]
train_data_probabilities: [0.4] # , 0.3, 0.3]
train_data_shuffle: True
val_dataset: "MapText_val"
val_data_shuffle: False

# training settings
batch_size: 4
num_epochs: 3000
num_samples_per_epoch: 200
lr: 0.0001
eval_every_epoch: 10
save_every_epoch: 500
warmup_ratio: 0.1
weight_decay: 0.01

# Device configuration
device: "cuda"

# Distributed training parameters
distributed: True
world_size: 1
local-rank: 0
dist_on_itp: False
dist_url: "env://"

version: 0